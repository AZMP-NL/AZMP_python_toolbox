'''
To generate AZMP score cards for bottom temperature

Uses pickled object generated by azmp_bottom_stats.py

Check /home/cyrf0006/AZMP/SAR_files


'''

import numpy as  np
import matplotlib.pyplot as plt
import pandas as pd
import os
#import unicodedata

# Parameters 
path = '/home/cyrf0006/AZMP/state_reports/bottomT/'
clim_year = [1981, 2010]
year_min = 1948
stn27_months = [5, 11]

#### -------------1. bottom temperature ---------------- ####
## 2J fall
infile = path + 'stats_2J_fall.pkl'
df = pd.read_pickle(infile)
df.index = pd.to_datetime(df.index) # update index to datetime
# compute std anom
df_clim = df[(df.index.year>=clim_year[0]) & (df.index.year<=clim_year[1])]
std_anom = (df-df_clim.mean(axis=0))/df_clim.std(axis=0)
# std anom for temperature
df['std_anom'] = std_anom['Tmean']
# keep only 2 columns
df = df[['Tmean', 'std_anom']]
df.index = df.index.year
df.to_csv('BT_2J_fall.dat', header=False, sep = ' ', float_format='%.2f')

## 3K fall
infile = path + 'stats_3K_fall.pkl'
df = pd.read_pickle(infile)
df.index = pd.to_datetime(df.index) # update index to datetime
# compute std anom
df_clim = df[(df.index.year>=clim_year[0]) & (df.index.year<=clim_year[1])]
std_anom = (df-df_clim.mean(axis=0))/df_clim.std(axis=0)
# std anom for temperature
df['std_anom'] = std_anom['Tmean']
# keep only 2 columns
df = df[['Tmean', 'std_anom']]
df.index = df.index.year
df.to_csv('BT_3K_fall.dat', header=False, sep = ' ', float_format='%.2f')

## 3LNO fall
infile = path + 'stats_3LNO_fall.pkl'
df = pd.read_pickle(infile)
df.index = pd.to_datetime(df.index) # update index to datetime
# compute std anom
df_clim = df[(df.index.year>=clim_year[0]) & (df.index.year<=clim_year[1])]
std_anom = (df-df_clim.mean(axis=0))/df_clim.std(axis=0)
# std anom for temperature
df['std_anom'] = std_anom['Tmean']
# keep only 2 columns
df = df[['Tmean', 'std_anom']]
df.index = df.index.year
df.to_csv('BT_3LNO_fall.dat', header=False, sep = ' ', float_format='%.2f')

## 3LNO spring
infile = path + 'stats_3LNO_spring.pkl'
df = pd.read_pickle(infile)
df.index = pd.to_datetime(df.index) # update index to datetime
# compute std anom
df_clim = df[(df.index.year>=clim_year[0]) & (df.index.year<=clim_year[1])]
std_anom = (df-df_clim.mean(axis=0))/df_clim.std(axis=0)
# std anom for temperature
df['std_anom'] = std_anom['Tmean']
# keep only 2 columns
df = df[['Tmean', 'std_anom']]
df.index = df.index.year
df.to_csv('BT_3LNO_spring.dat', header=False, sep = ' ', float_format='%.2f')

## 3Ps spring 
infile = path + 'stats_3Ps_spring.pkl'
df = pd.read_pickle(infile)
df.index = pd.to_datetime(df.index) # update index to datetime
# compute std anom
df_clim = df[(df.index.year>=clim_year[0]) & (df.index.year<=clim_year[1])]
std_anom = (df-df_clim.mean(axis=0))/df_clim.std(axis=0)
# std anom for temperature
df['std_anom'] = std_anom['Tmean']
# keep only 2 columns
df = df[['Tmean', 'std_anom']]
df.index = df.index.year
df.to_csv('BT_3Ps_spring.dat', header=False, sep = ' ', float_format='%.2f')

#### ------------- 2. winter NAO ---------------- ####
nao_file = '/home/cyrf0006/data/AZMP/indices/data.csv'
df = pd.read_csv(nao_file, header=1)
# Set index
df = df.set_index('Date')
df.index = pd.to_datetime(df.index, format='%Y%m')
# Select only DJF
df_winter = df[(df.index.month==12) | (df.index.month==1) | (df.index.month==2)]
# Start Dec-1950
df_winter = df_winter[df_winter.index>pd.to_datetime('1950-10-01')]
# Average 3 consecutive values (DJF average); We loose index.
df_winter = df_winter.groupby(np.arange(len(df_winter))//3).mean()
# Reset index using years only
year_unique = pd.unique(df.index.year)[1:,]
df_winter = df_winter.iloc[np.arange(0, year_unique.size)] # reduce if last month is december (belongs to following year)
df_winter.index = year_unique
df_winter.to_csv('NAO_DJF.dat', header=False, sep = ' ', float_format='%.2f')

#### ------------- 3. CIL ---------------- ####
# see /home/cyrf0006/AZMP/state_reports/ColbourneStuff/CIL_AZMP_SPRING_SUMMER_FALL.xlsx

# These timeseries are already calculated for the IROC (except for WB). 
# Check iroc_CIL_area.py and files in /home/cyrf0006/research/WGOH/IROC
df_SI = pd.read_csv('/home/cyrf0006/research/WGOH/IROC/CIL_area_SI.csv')
df_WB = pd.read_csv('/home/cyrf0006/research/WGOH/IROC/CIL_area_WB.csv')
df_BB = pd.read_csv('/home/cyrf0006/research/WGOH/IROC/CIL_area_BB.csv')
df_FC = pd.read_csv('/home/cyrf0006/research/WGOH/IROC/CIL_area_FC.csv')
df_SI.rename(columns={df_SI.columns[0]:'year'}, inplace=True)
df_WB.rename(columns={df_WB.columns[0]:'year'}, inplace=True)
df_BB.rename(columns={df_BB.columns[0]:'year'}, inplace=True)
df_FC.rename(columns={df_FC.columns[0]:'year'}, inplace=True)
df_SI.set_index('year', inplace=True)
df_WB.set_index('year', inplace=True)
df_BB.set_index('year', inplace=True)
df_FC.set_index('year', inplace=True) 
# cut timeseries
df_SI = df_SI[df_SI.index>=year_min]
df_WB = df_WB[df_WB.index>=year_min]
df_BB = df_BB[df_BB.index>=year_min]
df_FC = df_FC[df_FC.index>=year_min]
# Save timeseries
df_SI['interp_field'].to_csv('CIL_SealIsland_0C_Area.dat', header=False, sep = ' ', float_format='%.2f')
df_WB['interp_field'].to_csv('CIL_WhiteBay_0C_Area.dat', header=False, sep = ' ', float_format='%.2f')
df_BB['interp_field'].to_csv('CIL_Bonavista_0C_Area.dat', header=False, sep = ' ', float_format='%.2f')
df_FC['interp_field'].to_csv('CIL_FlemishCap_0C_Area.dat', header=False, sep = ' ', float_format='%.2f')

df_SI['station-ID'].to_csv('CIL_SealIsland_0C_Area_stationBased.dat', header=False, sep = ' ', float_format='%.2f')
df_WB['station-ID'].to_csv('CIL_WhiteBay_0C_Area_stationBased.dat', header=False, sep = ' ', float_format='%.2f')
df_BB['station-ID'].to_csv('CIL_Bonavista_0C_Area_stationBased.dat', header=False, sep = ' ', float_format='%.2f')
df_FC['station-ID'].to_csv('CIL_FlemishCap_0C_Area_stationBased.dat', header=False, sep = ' ', float_format='%.2f')



#### ------------- 4. Stn 27 ---------------- ####
# see /home/cyrf0006/AZMP/S27/station_27_stratification.xlsx
# Load pickled data
df_temp = pd.read_pickle('/home/cyrf0006/AZMP/state_reports/stn27/S27_temperature_monthly.pkl')
df_sal = pd.read_pickle('/home/cyrf0006/AZMP/state_reports/stn27/S27_salinity_monthly.pkl')
df_strat = pd.read_pickle('/home/cyrf0006/AZMP/state_reports/stn27/S27_stratif_monthly.pkl')

# Reduce to summer months and annual mean
df_temp = df_temp[(df_temp.index.month>=stn27_months[0]) & (df_temp.index.month<=stn27_months[1])].resample('As').mean()
df_sal = df_sal[(df_sal.index.month>=stn27_months[0]) & (df_sal.index.month<=stn27_months[1])].resample('As').mean()
df_strat = df_strat[(df_strat.index.month>=stn27_months[0]) & (df_strat.index.month<=stn27_months[1])].resample('As').mean()

# Temperature
T_0_btm = df_temp.mean(axis=1)
T_0_50 = df_temp[df_temp.columns[(df_temp.columns<=50)]].mean(axis=1)
T_170_btm = df_temp[df_temp.columns[(df_temp.columns>=170)]].mean(axis=1)
# Salinity
S_0_btm = df_sal.mean(axis=1)
S_0_50 = df_sal[df_sal.columns[(df_sal.columns<=50)]].mean(axis=1)
S_170_btm = df_sal[df_sal.columns[(df_sal.columns>=170)]].mean(axis=1)
# Statification
strat_5_50 = df_strat*45 # Note that this is not stratification, but density difference

# Merge 
df_stn27 = pd.concat([T_0_50, T_170_btm, S_0_50, strat_5_50], axis=1, keys=['Temp 0-50m', 'Temp 170-176m', 'Sal 0-50m', 'Strat 5-50m'])
df_stn27.index = df_stn27.index.year
df_stn27 = df_stn27[df_stn27.index>=year_min]
df_stn27.to_csv('S27_Integrated.dat', header=True, sep = ' ', na_rep='-99', float_format='%.3f')



# in Linux:  zip SAR_azmp-nl_2019.zip *.dat

